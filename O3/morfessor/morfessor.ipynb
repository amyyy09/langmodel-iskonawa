{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morfessor import BaselineModel, MorfessorIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('isc_words.txt', 'r') as f:\n",
    "    with open('isc_words_lower.txt', 'w') as f2:\n",
    "        for line in f:\n",
    "            f2.write(line.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set written to ./train_set.txt\n",
      "Test set written to ./test_set.txt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Load the word corpus (isc_words_lower)\n",
    "corpus_file_path = './isc_words_lower.txt'\n",
    "with open(corpus_file_path, 'r', encoding='utf-8') as file:\n",
    "    word_corpus = [line.strip() for line in file.readlines() if line.strip()]\n",
    "\n",
    "# Split the corpus into train and test sets (80% train, 20% test)\n",
    "random.shuffle(word_corpus)  # Shuffle the corpus to ensure random splitting\n",
    "split_index = int(len(word_corpus) * 0.8)  # 80% for training\n",
    "train_set = word_corpus[:split_index]\n",
    "test_set = word_corpus[split_index:]\n",
    "\n",
    "# Write the train and test sets to new files\n",
    "train_file_path = './train_set.txt'\n",
    "test_file_path = './test_set.txt'\n",
    "\n",
    "with open(train_file_path, 'w', encoding='utf-8') as train_file:\n",
    "    for word in train_set:\n",
    "        train_file.write(word + '\\n')\n",
    "\n",
    "with open(test_file_path, 'w', encoding='utf-8') as test_file:\n",
    "    for word in test_set:\n",
    "        test_file.write(word + '\\n')\n",
    "\n",
    "print(f\"Train set written to {train_file_path}\")\n",
    "print(f\"Test set written to {test_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Morfessor model\n",
    "model = BaselineModel()\n",
    "io_handler = MorfessorIO()\n",
    "\n",
    "# Load the corpus data\n",
    "data = io_handler.read_corpus_file(\"train_set.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_log_likelihood(model, test_data):\n",
    "    total_log_prob = 0.0\n",
    "    total_tokens = 0\n",
    "    for word in test_data:\n",
    "        # Segment the word\n",
    "        segmentation = model.viterbi_segment(word)\n",
    "        # Count tokens (morphemes) in the segmentation\n",
    "        total_tokens += len(segmentation)\n",
    "        # Calculate log-probability for each token\n",
    "        word_log_prob = sum([model.forward_logprob(morpheme) for morpheme in segmentation])\n",
    "        total_log_prob += word_log_prob\n",
    "    # Calculate average log probability\n",
    "    avg_log_prob = total_log_prob / total_tokens\n",
    "    # Calculate perplexity\n",
    "    perplexity = math.exp(-avg_log_prob)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........................................................\n",
      "...........................................................\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 61651.40449758041)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into the model and train\n",
    "model.load_data(data)\n",
    "model.train_batch(finish_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = io_handler.read_binary_file(\"morf_isc_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yoi n ai\n"
     ]
    }
   ],
   "source": [
    "segmentation= model.segment(\"yoinai\")\n",
    "segmented_word = \" \".join(segmentation)\n",
    "\n",
    "print(segmented_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_handler.write_binary_model_file(file_name=\"morf_isc_model.bin\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentations = model.get_segmentations()\n",
    "io_handler.write_segmentation_file(file_name=\"morf_isc_segm\",segmentations=segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructions = model.get_constructions()\n",
    "io_handler.write_lexicon_file(file_name=\"morf_isc_lex\", lexicon=constructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
