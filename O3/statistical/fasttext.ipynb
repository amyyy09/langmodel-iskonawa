{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.train_unsupervised('corpus.txt', model='skipgram', dim=64, ws=3)\n",
    "\n",
    "model.save_model('fasttext_model.bin')\n",
    "model.save_model('fasttext_model.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_word_vectors(model, num_samples=20):\n",
    "    \"\"\"Get random word vectors from the FastText model.\"\"\"\n",
    "    # Get the list of words in the vocabulary\n",
    "    words = model.get_words()\n",
    "    \n",
    "    # Randomly sample words\n",
    "    sampled_words = random.sample(words, num_samples)\n",
    "    \n",
    "    # Retrieve corresponding vectors\n",
    "    vectors = np.array([model.get_word_vector(word) for word in sampled_words])\n",
    "    \n",
    "    return sampled_words, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_2D(words, vectors, dimension='tsne'):\n",
    "    \"\"\"Visualize word vectors in 2D using t-SNE or PCA.\"\"\"\n",
    "    # Reduce dimensionality using t-SNE\n",
    "    if dimension == 'tsne':\n",
    "        perplexity = min(30, len(words) - 1)  # Ensure perplexity is less than the number of samples\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=0)\n",
    "        reduced_vectors = tsne.fit_transform(vectors)\n",
    "    # Reduce dimensionality using PCA\n",
    "    # elif dimension == 'pca':\n",
    "    #     pca = PCA(n_components=2)\n",
    "    #     reduced_vectors = pca.fit_transform(vectors)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dimension specified. Use 'tsne' or 'pca'.\")\n",
    "\n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(reduced_vectors[:, 0], reduced_vectors[:, 1])\n",
    "\n",
    "    # Annotate each point with the corresponding word\n",
    "    for i, word in enumerate(words):\n",
    "        plt.annotate(word, (reduced_vectors[i, 0], reduced_vectors[i, 1]), fontsize=9)\n",
    "\n",
    "    plt.title(f'2D Visualization of Word Vectors ({dimension.upper()})')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model(\"models/fasttext_32model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vectors = get_random_word_vectors(model,num_samples=20)\n",
    "visualize_embeddings_2D(words,vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vectors = load_vec_file('models/fasttext_32model.vec', num_samples=20)\n",
    "visualize_embeddings_2D(words, vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='skipgram', dim=100, ws=3, lr=0.1, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   59718 lr: -0.000162 avg.loss:  2.933889 ETA:   0h 0m 0s%\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='skipgram', dim=32, ws=3, lr=0.1, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   59890 lr: -0.000275 avg.loss:  2.932989 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='skipgram', dim=64, ws=3, lr=0.1, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   59352 lr:  0.000000 avg.loss:  2.936122 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='skipgram', dim=16, ws=3, lr=0.1, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   59578 lr:  0.000000 avg.loss:  2.876869 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='skipgram', dim=16, ws=3, lr=0.05, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   59471 lr:  0.000000 avg.loss:  3.276145 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=100, ws=3, lr=0.1, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   58820 lr:  0.000000 avg.loss:  3.199011 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=32, ws=3, lr=0.1, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   59630 lr: -0.000108 avg.loss:  3.182995 ETA:   0h 0m 0ss\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=64, ws=3, lr=0.1, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   59718 lr: -0.000181 avg.loss:  3.207726 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=16, ws=3, lr=0.1, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   59288 lr: -0.000107 avg.loss:  3.229246 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=16, ws=3, lr=0.05, epoch=10, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:   59624 lr: -0.000054 avg.loss:  3.624382 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=100, ws=5, lr=0.1, epoch=50, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:  149359 lr:  0.000000 avg.loss:  1.709613 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=32, ws=5, lr=0.1, epoch=50, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:  296740 lr:  0.000000 avg.loss:  1.673889 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=64, ws=5, lr=0.1, epoch=50, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:  149585 lr:  0.000000 avg.loss:  1.661034 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=16, ws=5, lr=0.1, epoch=50, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:  295987 lr:  0.000000 avg.loss:  1.800488 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=16, ws=5, lr=0.05, epoch=50, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:  294007 lr:  0.000000 avg.loss:  2.609519 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=32, ws=7, lr=0.1, epoch=50, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:  296381 lr:  0.000000 avg.loss:  1.644967 ETA:   0h 0m 0s\n",
    "- fasttext.train_unsupervised('data/isc_sentences.txt', model='cbow', dim=64, ws=7, lr=0.1, epoch=50, minCount=1)\n",
    "   - Progress: 100.0% words/sec/thread:  149516 lr:  0.000000 avg.loss:  1.670575 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuración final**\n",
    "- Modelo: cbow\n",
    "- Dimensión: 32\n",
    "- Window size: 7\n",
    "\n",
    "**Configuración alternativa**\n",
    "- Modelo: cbow\n",
    "- Dimensión: 64\n",
    "- Window size: 5\n",
    "\n",
    "**Entrenamiento**\n",
    "- Epochs: 50\n",
    "- Learning rate: 0.1\n",
    "- Min count: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones**\n",
    "- cbow es mejor que skipgram para el tamaño de datos que se tiene\n",
    "- Las mejores configuraciones son con dimensiones de 32 y 64. Las dimensiones de 16 y 100 no son tan buenas.\n",
    "- El window size de 7 es mejor con dimensiones más pequeñas y el window size de 5 es mejor con dimensiones más grandes. Porque con dimensiones más grandes, ya se tiene más información de contexto."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
